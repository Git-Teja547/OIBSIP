# ---------------------------------------------
# Project: Wine Quality Prediction
# ---------------------------------------------
# Objective: Predict wine quality based on chemical characteristics
# Models used: Random Forest, SGDClassifier, Support Vector Classifier (SVC)
# Libraries: Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn
# ---------------------------------------------

# Step 1: Import Required Libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import os

# Step 2: Load Dataset
df = pd.read_csv("WineQT.csv")   # <-- Ensure your CSV file is in the same folder
print("Dataset Loaded Successfully ✅")
print("Initial shape:", df.shape)
print("\nFirst 5 rows:\n", df.head())

# Step 3: Data Cleaning
print("\n--- Checking for missing values ---")
print(df.isnull().sum())

# Remove duplicates
duplicates = df.duplicated().sum()
df = df.drop_duplicates().reset_index(drop=True)
print(f"\nRemoved {duplicates} duplicate rows.")

# Fill missing numeric values (if any)
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
for c in numeric_cols:
    if df[c].isnull().any():
        df[c].fillna(df[c].median(), inplace=True)

print("\nMissing values after cleaning:\n", df.isnull().sum())

# Step 4: Data Summary
print("\nDataset Info:")
print(df.info())

print("\nStatistical Summary:")
print(df.describe())

# Step 5: Target and Feature Split
target_col = 'quality'  # target variable
X = df.drop(columns=[target_col])
y = df[target_col]

print("\nTarget column:", target_col)
print("Feature columns:", list(X.columns))

# Step 6: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print("\nData Split -> Train:", X_train.shape, " Test:", X_test.shape)

# Step 7: Define Models with Pipelines
pipelines = {
    "RandomForest": Pipeline([
        ("rf", RandomForestClassifier(n_estimators=200, random_state=42))
    ]),
    "SGD": Pipeline([
        ("scaler", StandardScaler()),
        ("sgd", SGDClassifier(max_iter=5000, tol=1e-3, random_state=42))
    ]),
    "SVC": Pipeline([
        ("scaler", StandardScaler()),
        ("svc", SVC(kernel='rbf', random_state=42))
    ])
}

# Step 8: Train Models and Evaluate
accuracies = {}
reports = {}
conf_matrices = {}

for name, pipe in pipelines.items():
    print(f"\nTraining {name} model...")
    pipe.fit(X_train, y_train)
    preds = pipe.predict(X_test)
    acc = accuracy_score(y_test, preds)
    accuracies[name] = acc
    reports[name] = classification_report(y_test, preds)
    conf_matrices[name] = confusion_matrix(y_test, preds)
    print(f"{name} Accuracy: {acc:.4f}")
    print("Classification Report:\n", classification_report(y_test, preds))

# Step 9: Compare Model Performance
print("\n--- Model Accuracies ---")
for name, acc in accuracies.items():
    print(f"{name}: {acc:.4f}")

# Step 10: Plot Confusion Matrices
for name, cm in conf_matrices.items():
    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f"Confusion Matrix - {name}")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.show()

# Step 11: Feature Importance (Random Forest)
rf_model = pipelines["RandomForest"].named_steps["rf"]
importances = pd.Series(rf_model.feature_importances_, index=X.columns)
plt.figure(figsize=(10,6))
sns.barplot(x=importances, y=importances.index, palette='viridis')
plt.title("Feature Importance - Random Forest")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.show()

# Step 12: Save Models
os.makedirs("wine_models", exist_ok=True)
for name, model in pipelines.items():
    with open(f"wine_models/{name}_model.pkl", "wb") as f:
        pickle.dump(model, f)
print("\nModels saved in 'wine_models/' folder ✅")

# Step 13: Summary Report
summary = {
    "RandomForest": accuracies["RandomForest"],
    "SGD": accuracies["SGD"],
    "SVC": accuracies["SVC"]
}
summary_df = pd.DataFrame(list(summary.items()), columns=['Model', 'Accuracy'])
print("\nFinal Model Performance Summary:\n", summary_df)
summary_df.to_csv("wine_models/model_summary.csv", index=False)

print("\n✅ Wine Quality Prediction Project Completed Successfully!")
